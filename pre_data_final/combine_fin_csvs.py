import os
import pandas as pd
from tqdm import tqdm
#å°†å¤„ç†å¥½çš„åˆå¹¶æˆå—çš„æ”»å‡»ä»¥åŠæ­£å¸¸æµé‡æ•°æ®åˆå¹¶æˆä¸€ä¸ªæ–‡ä»¶
# ğŸ“‚ å°å—æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆè¯·æ›¿æ¢ä¸ºä½ çš„è·¯å¾„ï¼‰
chunks_dir = r'D:\Desktop\C_G_A\CNN_GRU_ATTENTION\final_chunks'

# ğŸ’¾ æœ€ç»ˆåˆå¹¶åçš„å¤§æ–‡ä»¶è·¯å¾„
output_csv = r'D:\Desktop\C_G_A\CNN_GRU_ATTENTION\final_balanced_dataset.csv'

# ğŸ” è·å–æ‰€æœ‰å°å—æ–‡ä»¶ï¼ˆæŒ‰é¡ºåºæ’åºï¼‰
chunk_files = sorted([os.path.join(chunks_dir, f) for f in os.listdir(chunks_dir) if f.endswith('.csv')])

print(f"ğŸ“¦ å…±å‘ç° {len(chunk_files)} ä¸ªå°å—æ–‡ä»¶ï¼Œå¼€å§‹åˆå¹¶...")

# âœ… åˆå§‹åŒ–æ ‡ç­¾ç»Ÿè®¡å­—å…¸
label_counts = {0: 0, 1: 0}
total_records = 0
first_chunk = True

# ğŸ” åˆå¹¶è¿‡ç¨‹ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰
for chunk_file in tqdm(chunk_files, desc="ğŸ”„ åˆå¹¶è¿›åº¦"):
    chunk_df = pd.read_csv(chunk_file)

    # ç»Ÿè®¡æ ‡ç­¾æ•°é‡
    label_counts[0] += (chunk_df['label'] == 0).sum()
    label_counts[1] += (chunk_df['label'] == 1).sum()

    # ç»Ÿè®¡æ€»è®°å½•æ•°
    total_records += len(chunk_df)

    # è¿½åŠ å†™å…¥
    chunk_df.to_csv(output_csv, mode='a', index=False, header=first_chunk)
    first_chunk = False

print(f"\nâœ… åˆå¹¶å®Œæˆï¼Œå·²ä¿å­˜è‡³ï¼š{output_csv}")
print(f"ğŸ“Š åˆå¹¶åæ ‡ç­¾ç»Ÿè®¡ï¼šæ­£å¸¸æµé‡ï¼ˆlabel=0ï¼‰ï¼š{label_counts[0]} | æ”»å‡»æµé‡ï¼ˆlabel=1ï¼‰ï¼š{label_counts[1]}")
print(f"ğŸ“ˆ åˆå¹¶åæ€»è®°å½•æ•°ï¼š{total_records}")

# âœ… æ•°æ®æ˜¯å¦å¹³è¡¡è‡ªåŠ¨æ£€æµ‹
if label_counts[0] == label_counts[1]:
    print("âœ… æ•°æ®é›†å¹³è¡¡ï¼")
else:
    print("âš ï¸ æ•°æ®é›†ä¸å¹³è¡¡ï¼Œè¯·æ£€æŸ¥æ•°æ®é‡‡æ ·è¿‡ç¨‹ï¼")
