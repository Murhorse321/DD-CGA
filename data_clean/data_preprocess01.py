import pandas as pd
import os
from sklearn.preprocessing import LabelEncoder, MinMaxScaler

# ğŸ“ æ•°æ®è·¯å¾„
file_path = 'E:/CIC-DDoS/CSVs/CICDDoS2019_Merged.csv'

# ğŸ“ è¾“å‡ºç›®å½•
output_dir = 'processed_chunks'
os.makedirs(output_dir, exist_ok=True)

# âš™ï¸ åˆ†å—å¤§å°
chunk_size = 50000

# ğŸš« æ— ç”¨åˆ—åˆ—è¡¨ï¼ˆæ ¹æ®éœ€è¦å¯ç»§ç»­æ‰©å±•ï¼‰
useless_columns = [
    'flow id', 'source ip', 'source port', 'destination ip', 'destination port',
    'timestamp', 'simillarhttp', 'inbound', 'unnamed: 0',
     # âœ… æ–°å¢åˆ é™¤åˆ—
]

# âœ… åˆå§‹åŒ–å·¥å…·
label_encoder = LabelEncoder()
scaler = MinMaxScaler()

print("ğŸ“¥ æ­£åœ¨è¯»å–å¹¶åˆ†å—å¤„ç†æ•°æ®...")

for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunk_size, low_memory=False, encoding='utf-8')):
    print(f"\nğŸ“¦ æ­£åœ¨å¤„ç†ç¬¬ {i+1} å—æ•°æ®...")

    # âœ‚ï¸ æ¸…æ´—åˆ—å
    chunk.columns = chunk.columns.str.strip().str.lower()

    # ğŸ•µï¸â€â™‚ï¸ æ£€æŸ¥æ ‡ç­¾åˆ—æ˜¯å¦å­˜åœ¨
    if 'label' not in chunk.columns:
        print(f"âš ï¸ ç¬¬ {i+1} å—è·³è¿‡ï¼Œæœªæ‰¾åˆ° label åˆ—ã€‚")
        continue

    # ğŸš® åˆ é™¤æ— ç”¨åˆ—
    chunk = chunk.drop(columns=[col for col in useless_columns if col in chunk.columns], errors='ignore')

    # ğŸ§¹ åˆ é™¤å…¨ä¸ºç©ºçš„åˆ—
    chunk = chunk.dropna(axis=1, how='all')

    # ğŸ” æ£€æŸ¥ object ç±»å‹çš„éæ•°å€¼åˆ—ï¼ˆæ’é™¤ labelï¼‰
    non_numeric_cols = chunk.select_dtypes(include=['object']).columns.tolist()
    non_numeric_cols = [col for col in non_numeric_cols if col != 'label']
    if non_numeric_cols:
        print(f"âš ï¸ åˆ é™¤éæ•°å€¼åˆ—: {non_numeric_cols}")
        chunk = chunk.drop(columns=non_numeric_cols)

    # ğŸ·ï¸ ç¼–ç æ ‡ç­¾åˆ—ï¼ˆæ”»å‡»ç±»ä¸º 1ï¼Œæ­£å¸¸ä¸º 0ï¼‰
    chunk['label'] = label_encoder.fit_transform(chunk['label'])

    # âš ï¸ æ›¿æ¢ inf/-inf ä¸º NaNï¼Œå†ç»Ÿä¸€å¡« 0
    chunk = chunk.replace([float('inf'), float('-inf')], pd.NA).fillna(0)

    # ğŸ“Š å¯¹é™¤ 'label' å’Œ 'protocol' ä»¥å¤–çš„åˆ—è¿›è¡Œå½’ä¸€åŒ–
    feature_cols = [col for col in chunk.columns if col not in ['label', 'protocol']]
    chunk[feature_cols] = scaler.fit_transform(chunk[feature_cols])

    # ğŸ’¾ ä¿å­˜å¤„ç†ç»“æœ
    output_path = os.path.join(output_dir, f'processed_chunk_{i+1}.csv')
    chunk.to_csv(output_path, index=False)
    print(f"âœ… ç¬¬ {i+1} å—ä¿å­˜è‡³ï¼š{output_path}")

print("\nğŸ‰ æ‰€æœ‰æ•°æ®å¤„ç†å®Œæˆï¼")
