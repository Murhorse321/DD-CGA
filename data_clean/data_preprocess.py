import pandas as pd
import os
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
#æ•°æ®é¢„å¤„ç†â€”â€”åˆ æ‰null ä»¥åŠå…¶ä»–ä¸åˆæ³•çš„å€¼
# ğŸ“ æ–‡ä»¶è·¯å¾„ï¼ˆè¯·æ ¹æ®ä½ æ–‡ä»¶çš„ä½ç½®ä¿®æ”¹ï¼‰
file_path = 'E:\CIC-DDoS\CSVs\CICDDoS2019_Merged.csv'

# ğŸ“ è¾“å‡ºç›®å½•
output_dir = 'processed_chunks'
os.makedirs(output_dir, exist_ok=True)

# âš™ï¸ è®¾ç½®åˆ†å—å¤§å°
chunk_size = 50000

# ğŸš« æ— ç”¨åˆ—åˆ—è¡¨ï¼ˆå¯æ ¹æ®å®é™…è¿›ä¸€æ­¥ç²¾ç®€ï¼‰
useless_columns = [
    'flow id', 'source ip', 'source port', 'destination ip', 'destination port',
    'timestamp', 'simillarhttp', 'inbound', 'unnamed: 0'
]

# âœ… åˆå§‹åŒ–å·¥å…·
label_encoder = LabelEncoder()
scaler = MinMaxScaler()

print("ğŸ“¥ æ­£åœ¨è¯»å–å¹¶åˆ†å—å¤„ç†æ•°æ®...")

for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunk_size, low_memory=False, encoding='utf-8')):
    print(f"\nğŸ“¦ æ­£åœ¨å¤„ç†ç¬¬ {i+1} å—æ•°æ®...")

    # âœ‚ï¸ æ¸…æ´—åˆ—åï¼šå»ç©ºæ ¼ + å°å†™
    chunk.columns = chunk.columns.str.strip().str.lower()

    # ğŸ•µï¸â€â™‚ï¸ æ£€æŸ¥æ ‡ç­¾åˆ—
    if 'label' not in chunk.columns:
        print(f"âš ï¸ è·³è¿‡ç¬¬ {i+1} å—ï¼Œæœªæ‰¾åˆ° label åˆ—ã€‚")
        continue

    # ğŸš® åˆ é™¤æ— ç”¨åˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    chunk = chunk.drop(columns=[col for col in useless_columns if col in chunk.columns], errors='ignore')

    # ğŸ§¹ åˆ é™¤å…¨ä¸ºNaNçš„åˆ—ï¼ˆå¯èƒ½æŸäº›åˆ—åœ¨æŸäº›chunkä¸­ä¸ºç©ºï¼‰
    chunk = chunk.dropna(axis=1, how='all')

    # ğŸ” æ£€æŸ¥æ˜¯å¦ä»åŒ…å«éæ•°å€¼ç‰¹å¾
    non_numeric_cols = chunk.select_dtypes(include=['object']).columns.tolist()
    non_numeric_cols = [col for col in non_numeric_cols if col != 'label']

    # ğŸš« è‹¥å­˜åœ¨å…¶ä»–éæ•°å€¼åˆ—ï¼Œå…ˆåˆ é™¤ï¼ˆå¦‚åè®®ç±»å‹ï¼‰
    if non_numeric_cols:
        print(f"âš ï¸ åˆ é™¤éæ•°å€¼åˆ—: {non_numeric_cols}")
        chunk = chunk.drop(columns=non_numeric_cols)

    # ğŸ·ï¸ ç¼–ç æ ‡ç­¾åˆ—ï¼ˆæ”»å‡» -> 1ï¼Œæ­£å¸¸ -> 0ï¼‰
    chunk['label'] = label_encoder.fit_transform(chunk['label'])

    # âš ï¸ æ›¿æ¢ inf å’Œ -inf ä¸º NaNï¼Œå†ç»Ÿä¸€å¡« 0
    chunk = chunk.replace([float('inf'), float('-inf')], pd.NA)
    chunk = chunk.fillna(0)

    # ğŸ“Š ç‰¹å¾å½’ä¸€åŒ–ï¼ˆé™¤äº†æ ‡ç­¾åˆ—ï¼‰

    feature_cols = chunk.columns[chunk.columns != 'label']
    chunk[feature_cols] = scaler.fit_transform(chunk[feature_cols])

    # ğŸ’¾ ä¿å­˜å½“å‰å¤„ç†å—
    output_path = os.path.join(output_dir, f'processed_chunk_{i+1}.csv')
    chunk.to_csv(output_path, index=False)
    print(f"âœ… ç¬¬ {i+1} å—å¤„ç†å®Œæˆå¹¶ä¿å­˜è‡³ï¼š{output_path}")

print("\nğŸ‰ æ‰€æœ‰æ•°æ®å¤„ç†å®Œæˆï¼")
