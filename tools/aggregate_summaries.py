#èšåˆè„šæœ¬æ”¶é›†å¤šæ¬¡å®éªŒçš„ F1/Precision/Recall å‡å€¼Â±æ ‡å‡†å·®
#è¯»å–summary.jsonæ–‡ä»¶å°†æ‰€æœ‰çš„ç»“æœæ±‡æ€»èµ·æ¥
# tools/aggregate_summaries.py
#å¦‚æœä¸ç»™å‚æ•°å°±ç»Ÿè®¡æ‰€æœ‰ summary.jsonï¼Œç»™äº†å‚æ•°å°±åªç»Ÿè®¡æŒ‡å®šçš„
# tools/aggregate_summaries.py
#è¿è¡Œé…ç½®
# python tools/aggregate_summaries.py ^
#   results/tuning/20250908-142942/summary.json ^
#   -p "results/tuning/20250909*/summary.json" ^
#   -o results/tuning/my_agg_0909.csv

import argparse
import glob
import json
import os
import sys
import numpy as np
import pandas as pd

def stat_str(a: np.ndarray) -> str:
    a = np.asarray(a, dtype=float)
    if a.size == 0:
        return "NA"
    return f"{a.mean():.4f} Â± {a.std(ddof=0):.4f}"

def load_summary(path: str) -> dict:
    with open(path, "r", encoding="utf-8") as f:
        s = json.load(f)
    # å…¼å®¹/æ ¡éªŒå…³é”®å­—æ®µ
    req_root = ["outdir", "best_th_val", "test_at_best_val"]
    for k in req_root:
        if k not in s:
            raise ValueError(f"{path} ç¼ºå°‘å…³é”®å­—æ®µ: {k}")
    req_metrics = ["f1", "precision", "recall"]
    for k in req_metrics:
        if k not in s["test_at_best_val"]:
            raise ValueError(f"{path} ç¼ºå°‘ test_at_best_val.{k}")
    row = {
        "summary_path": os.path.normpath(path),
        "outdir": s["outdir"],
        "best_th_val": float(s["best_th_val"]),
        "test_f1": float(s["test_at_best_val"]["f1"]),
        "test_p": float(s["test_at_best_val"]["precision"]),
        "test_r": float(s["test_at_best_val"]["recall"]),
    }
    return row

def gather_files(positional_files, patterns):
    files = []
    # æ˜¾å¼æ–‡ä»¶
    if positional_files:
        files.extend(positional_files)
    # é€šé…ç¬¦ pattern
    for pat in patterns or []:
        files.extend(glob.glob(pat))
    # é»˜è®¤ï¼šå…¨é‡æ‰«æ
    if not files:
        files = glob.glob(os.path.join("results", "tuning", "*", "summary.json"))
    # å»é‡&æ’åº
    files = sorted(set(os.path.normpath(p) for p in files))
    return files

def main():
    ap = argparse.ArgumentParser(
        description="èšåˆ tune_threshold_and_eval.py äº§ç”Ÿçš„ summary.jsonï¼Œè®¡ç®—å‡å€¼Â±æ ‡å‡†å·®ç­‰ç»Ÿè®¡ã€‚"
    )
    ap.add_argument(
        "files", nargs="*", help="æƒ³è¦ç»Ÿè®¡çš„ summary.json æ–‡ä»¶è·¯å¾„ï¼ˆå¯å¤šä¸ªï¼‰ã€‚ä¸å¡«åˆ™æŒ‰é»˜è®¤ç›®å½•è‡ªåŠ¨æ‰«æã€‚"
    )
    ap.add_argument(
        "--pattern", "-p", action="append",
        help="å¯é€‰ï¼šé€šé…ç¬¦æ¨¡å¼ï¼ˆå¯å¤šæ¬¡æä¾›ï¼‰ï¼Œå¦‚ -p 'results/tuning/20250908*/summary.json'"
    )
    ap.add_argument(
        "--out", "-o", default=os.path.join("results", "tuning", "aggregate_summary.csv"),
        help="è¾“å‡ºCSVè·¯å¾„ï¼ˆé»˜è®¤ï¼šresults/tuning/aggregate_summary.csvï¼‰"
    )
    args = ap.parse_args()

    files = gather_files(args.files, args.pattern)
    if not files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½• summary.jsonã€‚è¯·æ£€æŸ¥ï¼š\n"
              "  1) æ˜¯å¦å·²è¿è¡Œ tools/tune_threshold_and_eval.py ç”Ÿæˆç»“æœï¼›\n"
              "  2) ä¼ å…¥çš„è·¯å¾„/æ¨¡å¼æ˜¯å¦æ­£ç¡®ã€‚", file=sys.stderr)
        sys.exit(1)

    rows = []
    bad = []
    for p in files:
        try:
            rows.append(load_summary(p))
        except Exception as e:
            bad.append((p, str(e)))

    if bad:
        print("âš ï¸ ä»¥ä¸‹æ–‡ä»¶è§£æå¤±è´¥ï¼ˆå·²è·³è¿‡ï¼‰ï¼š")
        for p, msg in bad:
            print(f"  - {p}: {msg}")

    if not rows:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„ summary è®°å½•ã€‚", file=sys.stderr)
        sys.exit(1)

    df = pd.DataFrame(rows).sort_values("outdir").reset_index(drop=True)

    # æ‰“å°é€æ¬¡å®éªŒ
    print("\n=== æ¯æ¬¡å®éªŒï¼ˆæŒ‰ outdir æ’åºï¼‰===")
    print(df.to_string(index=False))

    # ç»Ÿè®¡
    f1 = df["test_f1"].to_numpy()
    p  = df["test_p"].to_numpy()
    r  = df["test_r"].to_numpy()
    n  = len(df)

    print("\n=== æ±‡æ€»ç»Ÿè®¡ ===")
    print(f"æ ·æœ¬æ•° n = {n}")
    print(f"F1 (å‡å€¼Â±æ ‡å‡†å·®): {stat_str(f1)} | min={f1.min():.4f} max={f1.max():.4f}")
    print(f"P  (å‡å€¼Â±æ ‡å‡†å·®): {stat_str(p)}  | min={p.min():.4f}  max={p.max():.4f}")
    print(f"R  (å‡å€¼Â±æ ‡å‡†å·®): {stat_str(r)}  | min={r.min():.4f}  max={r.max():.4f}")

    # ä¿å­˜CSV
    out_path = os.path.normpath(args.out)
    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    df.to_csv(out_path, index=False, encoding="utf-8")
    print(f"\nğŸ’¾ å·²ä¿å­˜: {out_path}")

if __name__ == "__main__":
    main()
