# 03_stratified_sampling_clean.py
# -*- coding: utf-8 -*-

import os
import glob
import math
import pandas as pd
import numpy as np
from tqdm import tqdm

# ================= ğŸ§ª å®éªŒé…ç½®åŒºåŸŸ =================
INPUT_DIR = "data/step2_merged"
OUTPUT_FILE = "data/step3_balanced.csv"

# ã€ç›®æ ‡é…é¢ã€‘
TARGET_SAMPLES_PER_CLASS = 10000

RANDOM_SEED = 42
CHUNK_SIZE = 100000

# ã€æ ¸å¿ƒ 1ï¼šé»‘åå•ã€‘
# æ˜¾å¼å‰”é™¤å™ªå£°ç±»åˆ«ï¼Œä¿è¯æ•°æ®é›†çº¯å‡€
IGNORE_LABELS = [
    'WebDDoS',  # æ ·æœ¬è¿‡å°‘ (<500)ï¼Œå±äºå™ªå£°
     # å¦‚æœä½ ä¸æƒ³åˆå¹¶åˆ° UDP-lagï¼Œä¹Ÿå¯ä»¥å‰”é™¤ï¼Œä½†é€šå¸¸å»ºè®®ä¿ç•™å¹¶åˆå¹¶
    # å¦‚æœå‘ç°å…¶ä»–åªæœ‰å‡ ç™¾æ¡çš„æ€ªå¼‚ç±»åˆ«ï¼Œä¹Ÿå¯ä»¥åŠ åœ¨è¿™é‡Œ
]

# ã€æ ¸å¿ƒ 2ï¼šç±»åˆ«æ˜ å°„å­—å…¸ã€‘
# å°†åŒæºæ”»å‡»å½’ä¸€åŒ–
ATTACK_MAPPING = {
    # UDP å®¶æ—
    'DrDoS_UDP': 'UDP',
    'UDP': 'UDP',

    # LDAP å®¶æ—
    'DrDoS_LDAP': 'LDAP',
    'LDAP': 'LDAP',

    # MSSQL å®¶æ—
    'DrDoS_MSSQL': 'MSSQL',
    'MSSQL': 'MSSQL',

    # NetBIOS å®¶æ—
    'DrDoS_NetBIOS': 'NetBIOS',
    'NetBIOS': 'NetBIOS',

    # Syn å®¶æ—
    'Syn': 'Syn',

    # UDP-Lag æ‹¼å†™ä¿®æ­£ (æ³¨æ„ï¼šSyn å’Œ UDP-lag æ˜¯ä¸åŒçš„)
    'UDP-lag': 'UDPLag',
    'UDPLag': 'UDPLag',
}


# =================================================

def normalize_label(label):
    return str(label).strip()


def get_unified_class(filename):
    """æ–‡ä»¶å -> ç»Ÿä¸€ç±»åˆ«"""
    base = os.path.basename(filename)
    name_no_ext = os.path.splitext(base)[0]

    # å»é™¤æ—¥æœŸå‰ç¼€
    raw_name = name_no_ext
    for prefix in ["01-12_", "03-11_"]:
        if raw_name.startswith(prefix):
            raw_name = raw_name.replace(prefix, "")
            break

    # æ˜ å°„
    return ATTACK_MAPPING.get(raw_name, raw_name)


def main():
    if not os.path.exists(INPUT_DIR):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°ç›®å½• {INPUT_DIR}")
        return

    csv_files = glob.glob(os.path.join(INPUT_DIR, "*.csv"))
    if not csv_files:
        print("âŒ æœªæ‰¾åˆ° CSV æ–‡ä»¶ã€‚")
        return

    # 1. æ‰«æä¸å½’ç±»
    print("ğŸ” æ­£åœ¨æ‰«ææ–‡ä»¶å¹¶å»ºç«‹ç´¢å¼•...")
    class_file_map = {}

    for f in csv_files:
        unified_class = get_unified_class(f)

        # ğŸš« æ£€æŸ¥æ˜¯å¦åœ¨é»‘åå•ä¸­
        if unified_class in IGNORE_LABELS:
            print(f"  âš ï¸ è·³è¿‡è¢«å¿½ç•¥çš„ç±»åˆ«æ–‡ä»¶: {unified_class} ({os.path.basename(f)})")
            continue

        if unified_class not in class_file_map:
            class_file_map[unified_class] = []
        class_file_map[unified_class].append(f)

    print("-" * 40)
    print(f"âœ… æœ€ç»ˆçº³å…¥é‡‡æ ·çš„æ”»å‡»ç±»åˆ« ({len(class_file_map)} ç±»):")
    for k, v in class_file_map.items():
        print(f"     [{k}]: {len(v)} ä¸ªæºæ–‡ä»¶")
    print("-" * 40)

    final_dfs = []

    # 2.1 æå–è‰¯æ€§ (Benign)
    print("\nğŸ“¦ [1/2] æ­£åœ¨æå–è‰¯æ€§æµé‡ (Benign)...")
    total_benign = 0
    for f in tqdm(csv_files, desc="Scanning Benign"):
        # å³ä½¿æ˜¯è¢«å¿½ç•¥çš„ WebDDoS æ–‡ä»¶ï¼Œé‡Œé¢ä¹Ÿå¯èƒ½æœ‰ Benignï¼Œæ‰€ä»¥éƒ½è¦æ‰«ä¸€é
        try:
            chunks = []
            with pd.read_csv(f, chunksize=CHUNK_SIZE) as reader:
                for chunk in reader:
                    if 'label' not in chunk.columns: continue
                    chunk['label'] = chunk['label'].apply(normalize_label)

                    # æå– Benign
                    benign_part = chunk[chunk['label'].str.lower() == 'benign'].copy()
                    if not benign_part.empty:
                        benign_part['label'] = 'Benign'
                        chunks.append(benign_part)

            if chunks:
                df_b = pd.concat(chunks)
                final_dfs.append(df_b)
                total_benign += len(df_b)
        except Exception as e:
            print(f"  âš ï¸ è¯»å– {os.path.basename(f)} å¤±è´¥: {e}")

    print(f"  -> âœ… è‰¯æ€§æ ·æœ¬æ€»æ•°: {total_benign}")

    # 2.2 æå–æ”»å‡» (Attack)
    print(f"\nğŸ“¦ [2/2] æ­£åœ¨æå–æ”»å‡»æµé‡ (Target={TARGET_SAMPLES_PER_CLASS}/ç±»)...")

    for atk_class, file_list in class_file_map.items():
        num_files = len(file_list)
        quota_per_file = math.ceil(TARGET_SAMPLES_PER_CLASS / num_files)

        print(f"  -> å¤„ç†: {atk_class} (æ¯æ–‡ä»¶é™é¢ {quota_per_file})")

        class_collected = 0

        for f in file_list:
            file_collected_df = []
            with pd.read_csv(f, chunksize=CHUNK_SIZE) as reader:
                for chunk in reader:
                    if 'label' not in chunk.columns: continue
                    chunk['label'] = chunk['label'].apply(normalize_label)

                    # å‰”é™¤ Benign å’Œ é»‘åå•label (åŒé‡ä¿é™©)
                    # æœ‰æ—¶å€™ WebDDoS.csv é‡Œä¸ä»…æœ‰ Benign è¿˜æœ‰ WebDDoS æ ‡ç­¾
                    mask_atk = (chunk['label'].str.lower() != 'benign') & \
                               (~chunk['label'].isin(IGNORE_LABELS))

                    df_atk = chunk[mask_atk]
                    if df_atk.empty: continue

                    file_collected_df.append(df_atk)

            if not file_collected_df:
                continue

            df_file_total = pd.concat(file_collected_df, ignore_index=True)

            # æŠ½æ ·
            if len(df_file_total) > quota_per_file:
                df_sampled = df_file_total.sample(n=quota_per_file, random_state=RANDOM_SEED)
            else:
                df_sampled = df_file_total

            # é‡å‘½åä¸ºç»Ÿä¸€æ ‡ç­¾
            df_sampled = df_sampled.copy()
            df_sampled['label'] = atk_class

            final_dfs.append(df_sampled)
            class_collected += len(df_sampled)

        print(f"     âœ… å·²æ”¶é›† {atk_class}: {class_collected} æ¡")

    # 3. ä¿å­˜
    if not final_dfs:
        print("âŒ æœªæå–åˆ°æ•°æ®")
        return

    print("\nğŸ”„ åˆå¹¶ä¸æ‰“ä¹±...")
    full_df = pd.concat(final_dfs, ignore_index=True)
    full_df = full_df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)

    full_df['label_int'] = full_df['label'].apply(lambda x: 0 if x == 'Benign' else 1)

    print(f"ğŸ’¾ ä¿å­˜è‡³ {OUTPUT_FILE} ...")
    full_df.to_csv(OUTPUT_FILE, index=False)

    print("-" * 50)
    print("ğŸ‰ å®Œç¾æ•°æ®é›†æ„å»ºå®Œæˆï¼")
    print(full_df['label'].value_counts())
    print("-" * 50)


if __name__ == "__main__":
    main()