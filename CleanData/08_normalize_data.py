# 08_normalize_data.py
# -*- coding: utf-8 -*-

import os
import pandas as pd
import numpy as np
import joblib  # ç”¨äºä¿å­˜å½’ä¸€åŒ–å‚æ•°
from sklearn.preprocessing import MinMaxScaler

# ================= ğŸ§ª å®éªŒé…ç½® =================
# è¾“å…¥ï¼šStep 3.5 é”å®šçš„æœ€ç»ˆç‰¹å¾æ•°æ®
INPUT_DIR = "/CleanData/data/step5_final"
# è¾“å‡ºï¼šå½’ä¸€åŒ–åçš„æ•°æ® (å‡†å¤‡å–‚ç»™ PyTorch)
OUTPUT_DIR = "results/data/step6_normalized"
# Scaler ä¿å­˜è·¯å¾„ (é‡è¦!)
SCALER_PATH = "results/data/scaler.pkl"

# å½’ä¸€åŒ–èŒƒå›´ï¼š[0, 1] é€‚åˆè½¬åŒ–ä¸ºç°åº¦å›¾
FEATURE_RANGE = (0, 1)


# ===============================================

def main():
    if not os.path.exists(INPUT_DIR):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥ç›®å½• {INPUT_DIR}")
        return

    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

    print("ğŸš€ å¼€å§‹æ•°æ®å½’ä¸€åŒ– (MinMax Scaling)...")

    # 1. è¯»å–æ‰€æœ‰æ•°æ®é›†
    print("   æ­£åœ¨è¯»å– Train / Val / Test ...")
    df_train = pd.read_csv(os.path.join(INPUT_DIR, "train.csv"))
    df_val = pd.read_csv(os.path.join(INPUT_DIR, "val.csv"))
    df_test = pd.read_csv(os.path.join(INPUT_DIR, "test.csv"))

    # 2. åŒºåˆ† ç‰¹å¾åˆ— vs æ ‡ç­¾åˆ—
    # æˆ‘ä»¬ä¹‹å‰å·²ç»ä¿è¯äº†åˆ—ç»“æ„æ˜¯ [ç‰¹å¾...ç‰¹å¾, label, label_int]
    # è‡ªåŠ¨è¯†åˆ«æ’é™¤åˆ—
    exclude_cols = ['label', 'label_int']
    feature_cols = [c for c in df_train.columns if c not in exclude_cols]

    print(f"   æ£€æµ‹åˆ°ç‰¹å¾åˆ—æ•°: {len(feature_cols)} (åº”ä¸º 64)")

    # 3. æ‹Ÿåˆ Scaler (ä»…ä½¿ç”¨è®­ç»ƒé›†!)
    print("   [å…³é”®] æ­£åœ¨åŸºäºè®­ç»ƒé›†è®¡ç®— Min/Max ...")
    scaler = MinMaxScaler(feature_range=FEATURE_RANGE)

    # Fit: è¿™ä¸€æ­¥è®¡ç®—äº†æ¯ä¸ªç‰¹å¾åˆ—çš„ min å’Œ max
    scaler.fit(df_train[feature_cols])

    # ä¿å­˜ Scaler
    joblib.dump(scaler, SCALER_PATH)
    print(f"   ğŸ’¾ å½’ä¸€åŒ–å‚æ•°å·²ä¿å­˜è‡³: {SCALER_PATH}")

    # 4. è½¬æ¢å¹¶ä¿å­˜æ‰€æœ‰æ•°æ®é›†
    def process_and_save(df, name):
        # å¤åˆ¶ä¸€ä»½ï¼Œé¿å…ä¿®æ”¹åŸå˜é‡
        df_scaled = df.copy()

        # è½¬æ¢ç‰¹å¾åˆ—
        # æ³¨æ„ï¼šå¦‚æœæœ‰ç‰¹å¾å€¼è¶…è¿‡äº†è®­ç»ƒé›†çš„èŒƒå›´ï¼ˆæ¯”å¦‚æµ‹è¯•é›†å‡ºç°äº†æ›´å¤§çš„åŒ…ï¼‰ï¼Œ
        # MinMax ä¼šæŠŠå®ƒå˜æˆ >1 çš„æ•°ï¼Œè¿™æ˜¯æ­£å¸¸çš„ï¼ŒCNN èƒ½å¤„ç†ã€‚
        # å¦‚æœä½ æƒ³å¼ºåˆ¶æˆªæ–­åˆ° 1ï¼Œå¯ä»¥åŠ  clipï¼Œä½†é€šå¸¸ä¸éœ€è¦ã€‚
        df_scaled[feature_cols] = scaler.transform(df[feature_cols])

        # å®‰å…¨æ£€æŸ¥ï¼šå¤„ç†æå°‘æ•°å¯èƒ½å‡ºç°çš„ NaN (ä¾‹å¦‚æŸåˆ—æ–¹å·®æå°è®¡ç®—æº¢å‡º)
        df_scaled[feature_cols] = df_scaled[feature_cols].fillna(0)

        # ä¿å­˜
        save_path = os.path.join(OUTPUT_DIR, f"{name}.csv")
        df_scaled.to_csv(save_path, index=False)
        print(f"   -> {name.upper()} é›†å·²ä¿å­˜: {save_path}")

    process_and_save(df_train, "train")
    process_and_save(df_val, "val")
    process_and_save(df_test, "test")

    print("-" * 50)
    print("ğŸ‰ æ•°æ®é¢„å¤„ç†å…¨æµç¨‹å®Œç¾æ”¶å®˜ï¼")
    print(f"ğŸ“‚ æœ€ç»ˆæˆå“ä½äº: {OUTPUT_DIR}")
    print("   è¿™äº› CSV æ–‡ä»¶é‡Œçš„æ•°å€¼ç°åœ¨éƒ½åœ¨ 0 åˆ° 1 ä¹‹é—´ã€‚")
    print("   æ¯ä¸€è¡Œéƒ½å¯ä»¥ç›´æ¥ Reshape æˆä¸€ä¸ª 8x8 çš„ç°åº¦å›¾åƒã€‚")
    print("-" * 50)
    print("ä¸‹ä¸€æ­¥è®¡åˆ’ï¼š")
    print("ç¼–å†™ PyTorch çš„ Dataset Loaderï¼ŒæŠŠè¿™äº› CSV å˜æˆæ¨¡å‹èƒ½åƒçš„ Tensorã€‚")


if __name__ == "__main__":
    main()